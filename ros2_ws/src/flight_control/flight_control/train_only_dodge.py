import os
import time
from stable_baselines3 import PPO
from stable_baselines3.common.callbacks import CheckpointCallback
from only_dodge_env import OnlyDodgeEnv #Changeable

def main():
    """
    Lazy Survivor í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
    
    ëª©í‘œ: í™ˆ í¬ì§€ì…˜ ê·¼ì²˜ì—ì„œ ìµœì†Œí•œì˜ ì›€ì§ì„ìœ¼ë¡œ ì´ì•Œì„ íšŒí”¼í•˜ë©° ìƒì¡´
    """
    # 1. ë¡œê·¸ ë° ëª¨ë¸ ì €ì¥ ê²½ë¡œ ì„¤ì •
    run_id = time.strftime("%Y%m%d-%H%M%S")
    log_dir = f"./logs_only_dodge/{run_id}"
    model_dir = f"./models_only_dodge/{run_id}"
    
    os.makedirs(log_dir, exist_ok=True)
    os.makedirs(model_dir, exist_ok=True)

    print("="*60)
    print("ğŸ¯ Lazy Survivor Training Start!")
    print("="*60)
    print(f"ğŸ“Š Logs Directory:   {log_dir}")
    print(f"ğŸ’¾ Models Directory: {model_dir}")
    print(f"ğŸ® Environment:      OnlyDodgeEnv (Home Defense)")
    print("="*60)
    print()

    # 2. í™˜ê²½ ìƒì„±
    env = OnlyDodgeEnv()#Changeable

    # 3. ëª¨ë¸ ìƒì„± (PPO ì•Œê³ ë¦¬ì¦˜)
    # Lazy Survivorì— ìµœì í™”ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„°
    model = PPO.load(
        "./models_only_dodge/20260219-224246/lazy_survivor_ppo_final.zip",
        env=env,
        tensorboard_log=log_dir
    )
    # model = PPO(
    #     "MlpPolicy", 
    #     env, 
    #     verbose=1,
    #     tensorboard_log=log_dir,
    #     learning_rate=0.0003,      # í•™ìŠµë¥ 
    #     n_steps=2048,              # ì—…ë°ì´íŠ¸ ì „ ë°ì´í„° ìˆ˜ì§‘ëŸ‰
    #     batch_size=64,             # ë¯¸ë‹ˆë°°ì¹˜ í¬ê¸°
    #     ent_coef=0.01,             # íƒí—˜ ì¥ë ¤ (ë‚®ìŒ - ë³´ìˆ˜ì  í–‰ë™ ì„ í˜¸)
    #     gamma=0.99,                # í• ì¸ ê³„ìˆ˜
    #     gae_lambda=0.95,           # GAE lambda
    #     clip_range=0.2,            # PPO í´ë¦¬í•‘ ë²”ìœ„
    #     device="cpu"               # CPU ì‚¬ìš©
    # )

    # 4. ì¤‘ê°„ ì €ì¥ ì½œë°± (10ë§Œ ìŠ¤í…ë§ˆë‹¤ ëª¨ë¸ ì €ì¥)
    checkpoint_callback = CheckpointCallback(
        save_freq=100000, 
        save_path=model_dir,
        name_prefix="lazy_survivor_ppo"
    )

    # 5. í•™ìŠµ ì‹œì‘!
    print("Starting Training...")
    print("Metrics to Watch:")
    print("   - ep_len_mean: ìƒì¡´ ìŠ¤í… ìˆ˜ (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)")
    print("   - ep_rew_mean: í‰ê·  ë³´ìƒ (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)")
    print("   - ëª©í‘œ: ìµœì†Œ ì›€ì§ì„ìœ¼ë¡œ ìµœëŒ€ ìƒì¡´")
    print()
    
    model.learn(total_timesteps=500_000, callback=checkpoint_callback, reset_num_timesteps=False)

    # 6. ìµœì¢… ëª¨ë¸ ì €ì¥
    final_model_path = f"{model_dir}/lazy_survivor_ppo_final"
    model.save(final_model_path)
    
    print()
    print("="*60)
    print("âœ… Training Finished!")
    print("="*60)
    print(f"ğŸ’¾ Final Model Saved: {final_model_path}.zip")
    print(f"ğŸ“Š TensorBoard: tensorboard --logdir={log_dir}")
    print("="*60)

if __name__ == '__main__':
    main()
